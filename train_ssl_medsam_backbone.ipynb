{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from train_ssl_medsam_backbone import get_dataloaders, ModelFactory\n",
    "\n",
    "train, val, test = get_dataloaders()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "image = next(iter(train))[0]\n",
    "image = image.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 64, 64])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from medAI.utils.masking_generator import MaskingGenerator\n",
    "mask_gen = MaskingGenerator((64, 64), int(64 * 64 * 0.3), min_num_patches=16, max_num_patches=100)\n",
    "import torch \n",
    "\n",
    "def generate_masks(image):\n",
    "    masks = []\n",
    "    for _ in range(image.shape[0]):\n",
    "        masks.append(torch.from_numpy(mask_gen()).bool().to(image.device)) \n",
    "    return torch.stack(masks)\n",
    "\n",
    "generate_masks(image).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "from segment_anything.modeling.common import LayerNorm2d\n",
    "from medAI.utils.masking_generator import MaskingGenerator\n",
    "from medAI.modeling.swav import sinkhorn_knopp\n",
    "from copy import deepcopy   \n",
    "\n",
    "\n",
    "@torch.no_grad()\n",
    "def do_ema_update(teacher, student, alpha=0.999):\n",
    "    for teacher_param, student_param in zip(teacher.parameters(), student.parameters()):\n",
    "        teacher_param.data.mul_(alpha).add_(1 - alpha, student_param.data)\n",
    "\n",
    "\n",
    "class IBotStyleModel(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        encoder_transformer_dim=768,\n",
    "        proj_dim=512,\n",
    "        num_classes=1024,\n",
    "        feature_map_size=64,\n",
    "        min_num_patches=16,\n",
    "        max_num_patches=100,\n",
    "        mask_ratio=0.3,\n",
    "        ema_alpha=0.999,\n",
    "        lambda_=20,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.mask_gen = MaskingGenerator(\n",
    "            (feature_map_size, feature_map_size),\n",
    "            int(feature_map_size * feature_map_size * mask_ratio),\n",
    "            min_num_patches=min_num_patches,\n",
    "            max_num_patches=max_num_patches,\n",
    "        )\n",
    "        self.student = MaskableMedSAMWithProjection(encoder_transformer_dim, proj_dim, num_classes)\n",
    "        self.teacher = deepcopy(self.student)\n",
    "        self.ema_alpha = ema_alpha\n",
    "        self.lambda_ = lambda_  \n",
    "\n",
    "    def generate_masks(self, image):\n",
    "        masks = []\n",
    "        for _ in range(image.shape[0]):\n",
    "            masks.append(torch.from_numpy(self.mask_gen()).bool().to(image.device))\n",
    "        return torch.stack(masks)\n",
    "\n",
    "    def forward(self, image):\n",
    "        mask = self.generate_masks(image)\n",
    "        with torch.no_grad(): \n",
    "            target_token_scores = self.teacher(image, mask=None)\n",
    "            target_token_scores = target_token_scores.permute(0, 2, 3, 1)\n",
    "            target_token_scores = target_token_scores[mask]\n",
    "\n",
    "            # compute target distributions - sinkhorn_knopp centering\n",
    "            n_targets, n_sources = target_token_scores.shape\n",
    "            target_row_sum = torch.ones((n_targets, 1)).cuda()\n",
    "            target_col_sum = torch.ones((n_sources, 1)).cuda() * n_targets / n_sources \n",
    "            K = torch.exp(target_token_scores * self.lambda_)\n",
    "            target_dist = sinkhorn_knopp(K, target_row_sum, target_col_sum, n_iters=3)\n",
    "\n",
    "        student_token_scores = self.student(image, mask=mask)\n",
    "        student_token_scores = student_token_scores.permute(0, 2, 3, 1)\n",
    "        student_token_scores = student_token_scores[mask]\n",
    "\n",
    "        loss = torch.sum(-target_dist * torch.log_softmax(student_token_scores, dim=-1), dim=-1).mean()\n",
    "\n",
    "        return loss\n",
    "\n",
    "    def ema_update(self):\n",
    "        do_ema_update(self.teacher, self.student, self.ema_alpha)\n",
    "\n",
    "    @property\n",
    "    def image_encoder(self):\n",
    "        return self.student.encoder\n",
    "\n",
    "\n",
    "class MaskableMedSAMWithProjection(nn.Module):\n",
    "    def __init__(self, encoder_transformer_dim=768, proj_dim=512, ntokens=1024):\n",
    "        super().__init__()\n",
    "        self.encoder = ModelFactory._medsam_image_encoder()\n",
    "\n",
    "        self.proj = nn.Sequential(\n",
    "            nn.Conv2d(256, proj_dim, 1),\n",
    "            LayerNorm2d(proj_dim),\n",
    "            nn.Conv2d(512, ntokens, 1),\n",
    "        )\n",
    "\n",
    "        self.mask_token = torch.nn.Parameter(torch.randn(encoder_transformer_dim))\n",
    "\n",
    "    def forward(self, image, mask=None):\n",
    "        embed = self.encoder.patch_embed(image)  # B, N, H, W\n",
    "\n",
    "        if mask is not None:\n",
    "            embed[mask] = self.mask_token\n",
    "        \n",
    "        # do the rest of the forward pass\n",
    "        x = embed\n",
    "\n",
    "        if self.encoder.pos_embed is not None:\n",
    "            x = x + self.encoder.pos_embed\n",
    "\n",
    "        for blk in self.encoder.blocks:\n",
    "            x = blk(x)\n",
    "\n",
    "        x = self.encoder.neck(x.permute(0, 3, 1, 2))\n",
    "        x = self.proj(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "model = IBotStyleModel().cuda()\n",
    "loss = model(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(6.8620, device='cuda:0', grad_fn=<MeanBackward0>)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4908, 1024])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out_scores.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_targets, n_sources = out_scores.shape\n",
    "target_row_sum = torch.ones((n_targets, 1)).cuda()\n",
    "target_col_sum = torch.ones((n_sources, 1)).cuda() * n_targets / n_sources\n",
    "\n",
    "K = torch.exp(out_scores * 20)\n",
    "\n",
    "out = sinkhorn_knopp(K, target_row_sum, target_col_sum, n_iters=3, last_norm='row')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1.0000, 1.0000, 1.0000,  ..., 1.0000, 1.0000, 1.0000], device='cuda:0',\n",
       "       grad_fn=<SumBackward1>)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "out.sum(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'out' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/h/pwilson/projects/sam_cancer_detection/train_ssl_medsam_backbone.ipynb Cell 7\u001b[0m line \u001b[0;36m2\n\u001b[1;32m      <a href='vscode-notebook-cell://tunnel%2Bvector-cluster/h/pwilson/projects/sam_cancer_detection/train_ssl_medsam_backbone.ipynb#X24sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mmatplotlib\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mpyplot\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mplt\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell://tunnel%2Bvector-cluster/h/pwilson/projects/sam_cancer_detection/train_ssl_medsam_backbone.ipynb#X24sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m plt\u001b[39m.\u001b[39mimshow(out\u001b[39m.\u001b[39mdetach()\u001b[39m.\u001b[39mcpu()\u001b[39m.\u001b[39mnumpy() \u001b[39m*\u001b[39m \u001b[39m10000\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'out' is not defined"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.imshow(out.detach().cpu().numpy() * 10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ True,  True,  True,  True,  True,  True, False,  True,  True,  True,\n",
       "         True,  True,  True,  True, False,  True,  True,  True,  True,  True,\n",
       "        False,  True, False,  True,  True,  True,  True,  True, False,  True,\n",
       "         True, False,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True, False,  True,\n",
       "         True,  True,  True,  True, False,  True,  True, False,  True,  True,\n",
       "         True,  True,  True,  True,  True, False,  True,  True,  True,  True,\n",
       "         True,  True, False,  True,  True,  True, False,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True, False,\n",
       "         True,  True,  True,  True,  True,  True, False, False,  True,  True,\n",
       "         True,  True,  True,  True, False,  True,  True,  True,  True,  True,\n",
       "         True,  True, False, False,  True, False,  True,  True,  True,  True,\n",
       "        False, False, False,  True,  True,  True,  True,  True, False,  True,\n",
       "         True, False,  True,  True,  True,  True,  True,  True, False,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True, False,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True, False,  True,  True,\n",
       "         True,  True,  True, False,  True, False, False,  True,  True,  True,\n",
       "         True, False,  True,  True,  True,  True, False,  True,  True,  True,\n",
       "         True,  True,  True,  True, False,  True,  True,  True,  True,  True,\n",
       "         True, False,  True,  True, False, False,  True, False,  True,  True,\n",
       "         True,  True,  True, False,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True, False,  True, False,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        False,  True,  True,  True,  True,  True,  True, False,  True, False,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True, False,  True,\n",
       "         True,  True,  True,  True,  True,  True, False,  True, False,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True, False,  True,  True, False,  True,  True,  True, False,\n",
       "         True,  True,  True,  True,  True, False,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True, False,  True, False,  True,\n",
       "        False,  True,  True, False,  True,  True,  True, False,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True, False,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True, False,  True,  True,  True,  True,\n",
       "        False,  True,  True,  True,  True,  True, False,  True, False, False,\n",
       "        False,  True, False,  True,  True,  True,  True, False,  True,  True,\n",
       "         True,  True,  True,  True, False,  True, False,  True, False,  True,\n",
       "        False,  True,  True,  True,  True,  True,  True, False,  True,  True,\n",
       "         True,  True, False,  True,  True,  True,  True,  True,  True,  True,\n",
       "        False,  True,  True,  True,  True,  True, False,  True,  True,  True,\n",
       "         True, False,  True, False,  True, False,  True,  True,  True,  True,\n",
       "         True,  True,  True, False,  True, False, False, False, False,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True, False,  True,  True,\n",
       "         True, False,  True, False,  True,  True,  True,  True,  True, False,\n",
       "         True, False,  True,  True, False,  True,  True,  True,  True,  True,\n",
       "        False,  True,  True,  True,  True, False,  True, False,  True,  True,\n",
       "         True,  True,  True, False, False,  True, False, False,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True, False,  True,\n",
       "        False,  True,  True,  True, False,  True,  True,  True, False,  True,\n",
       "         True, False,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True, False, False,  True, False,  True,  True,  True,\n",
       "        False, False,  True,  True, False,  True,  True,  True,  True,  True,\n",
       "        False,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True, False, False,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "        False, False,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True, False, False, False,  True,  True, False,\n",
       "         True,  True, False,  True,  True, False,  True,  True,  True, False,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True, False, False,\n",
       "         True, False,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True, False,  True, False, False,  True,  True, False, False,\n",
       "         True, False,  True,  True,  True,  True, False,  True, False,  True,\n",
       "         True,  True,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True, False,  True,  True,  True,\n",
       "         True,  True, False,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True, False,  True,  True,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True, False,  True, False,  True,  True,  True,\n",
       "         True,  True,  True,  True, False,  True,  True, False,  True,  True,\n",
       "         True, False,  True, False,  True,  True,  True,  True,  True,  True,\n",
       "         True,  True,  True,  True,  True,  True, False,  True, False,  True,\n",
       "         True,  True, False,  True,  True,  True,  True,  True])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next(iter(model.student.state_dict().values())) == next(iter(model.teacher.state_dict().values()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 1024, 64, 64])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "_.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ImageEncoderViT(\n",
       "  (patch_embed): PatchEmbed(\n",
       "    (proj): Conv2d(3, 768, kernel_size=(16, 16), stride=(16, 16))\n",
       "  )\n",
       "  (blocks): ModuleList(\n",
       "    (0-11): 12 x Block(\n",
       "      (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "      (attn): Attention(\n",
       "        (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
       "        (proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "      )\n",
       "      (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "      (mlp): MLPBlock(\n",
       "        (lin1): Linear(in_features=768, out_features=3072, bias=True)\n",
       "        (lin2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        (act): GELU(approximate='none')\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (neck): Sequential(\n",
       "    (0): Conv2d(768, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
       "    (1): LayerNorm2d()\n",
       "    (2): Conv2d(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
       "    (3): LayerNorm2d()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from copy import deepcopy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 64, 64, 768])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder.patch_embed(image).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4, 3, 1024, 1024])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from mas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[-2.2027e-02, -8.9647e-03, -1.7505e-02,  ..., -2.8102e-02,\n",
       "           -2.8458e-02, -2.1480e-02],\n",
       "          [-1.4018e-02, -1.3767e-02, -2.2677e-02,  ..., -1.2591e-02,\n",
       "           -1.0554e-02, -6.5527e-03],\n",
       "          [-8.7758e-03, -2.1652e-02, -1.2533e-02,  ..., -2.1075e-02,\n",
       "           -6.1827e-03, -1.4495e-02],\n",
       "          ...,\n",
       "          [-1.2857e-02, -1.1874e-02, -1.3135e-02,  ..., -1.6245e-02,\n",
       "           -9.1269e-03, -1.9114e-02],\n",
       "          [-6.8033e-03, -9.6007e-04, -1.0340e-02,  ..., -8.4152e-03,\n",
       "           -8.4766e-03, -1.1661e-02],\n",
       "          [-1.8129e-02, -1.1930e-02, -1.7203e-02,  ..., -1.8661e-02,\n",
       "           -2.0748e-02, -2.2367e-02]],\n",
       "\n",
       "         [[-1.1878e-01, -5.9102e-02, -7.6664e-02,  ...,  9.4831e-03,\n",
       "           -9.0445e-02,  6.7099e-03],\n",
       "          [-8.2192e-02, -1.0537e-01, -4.9334e-02,  ..., -1.1747e-02,\n",
       "           -4.1459e-02, -7.9624e-02],\n",
       "          [-4.2098e-02, -8.5422e-02, -1.2441e-01,  ..., -5.0162e-03,\n",
       "           -1.1572e-01,  2.7252e-02],\n",
       "          ...,\n",
       "          [-1.6200e-01, -9.0348e-02, -7.6862e-02,  ..., -7.7577e-02,\n",
       "           -1.6949e-02,  6.3520e-02],\n",
       "          [-1.4452e-01, -8.0334e-02, -8.0338e-02,  ..., -3.6407e-02,\n",
       "           -1.3781e-01, -9.8240e-02],\n",
       "          [-1.8759e-01, -1.7662e-01, -3.1186e-02,  ..., -1.2993e-01,\n",
       "           -2.1115e-01, -4.6202e-02]],\n",
       "\n",
       "         [[-8.5540e-02, -6.2924e-02, -6.8930e-02,  ..., -1.0896e-02,\n",
       "           -7.4971e-03, -5.2491e-02],\n",
       "          [-8.8690e-03, -2.0427e-02, -6.1528e-03,  ..., -4.7686e-03,\n",
       "           -2.8977e-02, -1.7231e-02],\n",
       "          [-2.7015e-02, -4.5018e-02, -6.5404e-02,  ..., -2.4021e-02,\n",
       "           -3.0863e-02, -5.0271e-03],\n",
       "          ...,\n",
       "          [ 1.3939e-02, -1.4076e-02,  2.7252e-02,  ...,  4.1471e-02,\n",
       "            7.7747e-02,  4.9951e-02],\n",
       "          [-3.9617e-03, -2.2622e-02,  5.7194e-03,  ...,  3.5335e-02,\n",
       "            5.9763e-02,  5.3832e-03],\n",
       "          [ 1.6525e-02, -2.1004e-02,  1.4237e-02,  ...,  3.2078e-02,\n",
       "            4.5718e-02,  2.4512e-02]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[-1.5046e-01, -9.4742e-02, -1.9646e-02,  ..., -4.3525e-02,\n",
       "           -5.3729e-02,  2.7570e-02],\n",
       "          [-1.4610e-01, -7.7333e-02, -8.4507e-02,  ...,  2.8048e-02,\n",
       "           -2.6937e-02, -1.9839e-02],\n",
       "          [-1.3996e-01, -8.8680e-02, -1.0773e-02,  ...,  5.0175e-02,\n",
       "           -7.1122e-02, -7.7775e-03],\n",
       "          ...,\n",
       "          [-4.0693e-02, -7.4851e-03,  8.9812e-02,  ...,  9.7073e-02,\n",
       "            3.4913e-02, -2.8077e-02],\n",
       "          [-8.5433e-02,  2.4794e-03,  2.8175e-02,  ...,  1.2751e-01,\n",
       "            3.3878e-02,  7.9573e-03],\n",
       "          [-9.5621e-02,  2.4089e-02,  1.1328e-01,  ...,  1.2150e-01,\n",
       "            3.8524e-02,  1.1489e-01]],\n",
       "\n",
       "         [[ 6.9694e-02,  1.5512e-01,  1.6134e-01,  ...,  1.0938e-01,\n",
       "            1.4412e-01,  6.6879e-02],\n",
       "          [ 5.2101e-02,  1.6820e-01,  1.9065e-01,  ...,  1.6447e-01,\n",
       "            2.3683e-01,  2.0168e-01],\n",
       "          [ 5.2044e-02,  1.7666e-01,  1.5996e-01,  ...,  2.2753e-01,\n",
       "            2.0834e-01,  1.7555e-01],\n",
       "          ...,\n",
       "          [ 9.3183e-02,  1.3322e-01,  2.3926e-01,  ...,  2.4102e-01,\n",
       "            1.4995e-01,  2.2102e-01],\n",
       "          [ 2.9302e-02,  8.7516e-02,  2.3217e-01,  ...,  1.6877e-01,\n",
       "            1.3471e-01,  2.0926e-01],\n",
       "          [ 1.0757e-02,  2.0319e-01,  1.9085e-01,  ...,  2.1812e-01,\n",
       "            1.0771e-01,  2.3490e-01]],\n",
       "\n",
       "         [[-9.2151e-02,  4.9051e-02,  7.8929e-02,  ...,  8.5728e-02,\n",
       "           -4.2451e-02, -9.4487e-02],\n",
       "          [-8.9582e-02, -7.8293e-02, -6.7479e-02,  ..., -1.7810e-02,\n",
       "            7.3610e-02,  1.4570e-02],\n",
       "          [-1.2050e-01,  3.7340e-02,  4.1490e-02,  ...,  4.6160e-02,\n",
       "            2.7425e-02, -1.7698e-03],\n",
       "          ...,\n",
       "          [ 5.3989e-02, -4.7333e-02,  3.4962e-04,  ...,  4.9457e-02,\n",
       "            9.2409e-02, -5.7444e-02],\n",
       "          [-6.6427e-02,  6.9211e-03,  3.7405e-02,  ...,  6.2346e-02,\n",
       "            3.1992e-02,  5.2950e-02],\n",
       "          [-3.9533e-02, -3.9218e-02,  6.5620e-02,  ...,  5.9540e-02,\n",
       "           -2.0214e-02,  8.9365e-02]]],\n",
       "\n",
       "\n",
       "        [[[-1.4327e-02, -2.1490e-02, -1.5422e-02,  ..., -1.2628e-02,\n",
       "           -1.3136e-02, -6.8329e-03],\n",
       "          [-1.0906e-02, -5.8328e-03, -1.7585e-02,  ..., -1.0567e-02,\n",
       "           -1.5152e-02, -1.6418e-02],\n",
       "          [-1.7608e-02, -1.4138e-02, -5.6391e-03,  ..., -7.4363e-03,\n",
       "           -1.8226e-02, -5.0366e-03],\n",
       "          ...,\n",
       "          [-1.2794e-02, -1.4993e-02, -1.4845e-02,  ..., -1.4860e-03,\n",
       "           -1.4231e-02, -1.1337e-02],\n",
       "          [-1.2051e-02, -9.6264e-03, -1.7927e-02,  ..., -8.9508e-03,\n",
       "           -8.4259e-03, -1.0428e-02],\n",
       "          [-2.0930e-02, -1.6497e-02, -2.0305e-02,  ..., -1.1059e-02,\n",
       "           -1.0392e-02, -1.8187e-02]],\n",
       "\n",
       "         [[-3.7395e-02, -9.2698e-02,  6.8592e-02,  ...,  7.3610e-02,\n",
       "           -7.6634e-02, -2.1220e-02],\n",
       "          [-5.0000e-02, -9.2625e-02, -5.2094e-02,  ...,  1.5134e-01,\n",
       "            1.2230e-01,  2.0129e-02],\n",
       "          [-2.2075e-01, -9.5199e-02, -1.4279e-01,  ..., -1.2947e-01,\n",
       "           -3.8753e-02,  1.4809e-02],\n",
       "          ...,\n",
       "          [-1.5758e-01, -1.2667e-01, -4.2157e-02,  ..., -3.0865e-02,\n",
       "           -2.3620e-02, -3.6076e-02],\n",
       "          [-1.5751e-01, -1.9195e-01, -7.3789e-02,  ..., -1.9882e-02,\n",
       "           -9.3358e-02, -7.5318e-02],\n",
       "          [-1.7472e-01, -2.0080e-01, -1.5473e-01,  ..., -1.0213e-01,\n",
       "           -1.3339e-01, -1.1481e-01]],\n",
       "\n",
       "         [[-7.6387e-02, -7.6079e-02, -6.1786e-02,  ..., -3.5467e-02,\n",
       "           -3.0752e-02, -2.4519e-02],\n",
       "          [ 8.8776e-03, -4.9222e-02, -3.4084e-02,  ..., -8.2950e-03,\n",
       "            4.3261e-03, -3.1323e-03],\n",
       "          [-3.8316e-02,  8.1538e-04, -8.5383e-03,  ...,  4.1068e-02,\n",
       "            4.7357e-02, -1.0875e-03],\n",
       "          ...,\n",
       "          [ 3.3036e-02,  7.2157e-03, -2.2073e-03,  ...,  4.1164e-02,\n",
       "            1.5408e-02,  2.4144e-02],\n",
       "          [ 2.3122e-02, -3.9677e-02, -8.4430e-03,  ...,  2.8995e-02,\n",
       "            3.4796e-02,  3.8143e-02],\n",
       "          [ 3.8022e-02,  1.8076e-02, -7.2921e-04,  ...,  4.6593e-02,\n",
       "            4.7842e-02, -5.1825e-02]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[-8.0376e-02, -7.5236e-02, -2.2402e-02,  ..., -1.2106e-03,\n",
       "           -7.7622e-02, -8.3818e-02],\n",
       "          [-1.5319e-01, -9.8749e-02, -3.4688e-02,  ..., -1.2506e-02,\n",
       "           -4.0366e-03,  2.0892e-02],\n",
       "          [-1.2838e-01,  2.5034e-02,  2.6460e-02,  ...,  4.2666e-02,\n",
       "            1.0189e-03,  7.6217e-02],\n",
       "          ...,\n",
       "          [-7.2938e-02,  5.6706e-02,  1.1025e-01,  ...,  1.1616e-01,\n",
       "            5.2375e-02,  9.3114e-02],\n",
       "          [-5.9782e-02,  2.8423e-02,  7.5550e-02,  ...,  7.4537e-02,\n",
       "            3.9042e-02,  8.1136e-02],\n",
       "          [-1.0766e-01,  6.9552e-02,  6.8356e-02,  ...,  1.9941e-02,\n",
       "            2.8241e-04,  4.5754e-02]],\n",
       "\n",
       "         [[-7.9102e-03,  1.1905e-01,  9.1368e-02,  ...,  6.0406e-02,\n",
       "            9.8611e-02,  5.2251e-02],\n",
       "          [ 1.1907e-01,  1.7627e-01,  1.9832e-01,  ...,  2.5471e-01,\n",
       "            2.2219e-01,  2.5698e-01],\n",
       "          [ 1.4001e-01,  2.1760e-01,  2.5886e-01,  ...,  1.5739e-01,\n",
       "            1.9586e-01,  2.4619e-01],\n",
       "          ...,\n",
       "          [ 1.6704e-02,  1.1009e-01,  1.2968e-01,  ...,  1.6435e-01,\n",
       "            1.4738e-01,  1.5401e-01],\n",
       "          [ 3.1167e-02,  1.3183e-01,  1.8855e-01,  ...,  1.4254e-01,\n",
       "            1.5001e-01,  2.2315e-01],\n",
       "          [ 9.6961e-02,  1.8438e-01,  1.6144e-01,  ...,  1.7804e-01,\n",
       "            1.2858e-01,  1.4780e-01]],\n",
       "\n",
       "         [[-1.9951e-02, -6.4094e-02,  1.5142e-03,  ...,  9.5424e-03,\n",
       "            1.2310e-02, -3.9843e-02],\n",
       "          [-1.3121e-02, -1.1152e-02,  2.6690e-02,  ...,  5.2024e-02,\n",
       "            3.9853e-02, -1.3617e-01],\n",
       "          [-4.1058e-02, -4.5485e-02, -3.2745e-02,  ...,  2.7127e-02,\n",
       "            2.5907e-02,  1.3776e-01],\n",
       "          ...,\n",
       "          [ 1.6363e-02, -1.8671e-02, -5.5254e-02,  ...,  4.7999e-02,\n",
       "            7.0393e-02, -9.4470e-02],\n",
       "          [ 4.2371e-02,  1.7959e-02,  3.3054e-02,  ...,  1.4101e-02,\n",
       "            1.1461e-01, -2.8043e-03],\n",
       "          [-1.1075e-02, -1.0454e-01, -1.2200e-02,  ...,  6.4269e-03,\n",
       "            4.0343e-02,  8.0959e-03]]],\n",
       "\n",
       "\n",
       "        [[[-1.9942e-02, -1.8314e-02, -1.8591e-02,  ..., -1.3166e-02,\n",
       "           -1.8580e-02, -3.1501e-02],\n",
       "          [-9.4146e-03, -1.4484e-02, -1.0608e-02,  ..., -1.5397e-02,\n",
       "           -1.7235e-02, -1.3591e-02],\n",
       "          [-1.9328e-02, -2.2764e-02, -3.9547e-03,  ..., -1.3921e-02,\n",
       "           -1.3969e-02, -2.8891e-02],\n",
       "          ...,\n",
       "          [-9.4936e-04, -2.3399e-03, -1.1657e-02,  ..., -2.5216e-03,\n",
       "           -1.2535e-02, -1.8094e-02],\n",
       "          [-1.6458e-02, -1.3037e-02, -9.5298e-03,  ..., -1.1060e-02,\n",
       "           -9.6071e-03, -1.5078e-02],\n",
       "          [-2.0152e-02, -4.3887e-03, -8.3105e-03,  ..., -1.5036e-02,\n",
       "           -7.1839e-03, -2.7200e-02]],\n",
       "\n",
       "         [[-3.6850e-02, -5.9138e-02, -5.7844e-02,  ...,  2.0680e-02,\n",
       "           -1.6842e-02, -3.9968e-03],\n",
       "          [-9.9932e-02,  1.4460e-02, -2.2713e-02,  ..., -5.5658e-03,\n",
       "           -1.6057e-02,  4.6251e-02],\n",
       "          [-1.2423e-01, -7.3273e-02, -1.5069e-01,  ...,  3.5189e-03,\n",
       "           -4.3297e-03, -3.3654e-03],\n",
       "          ...,\n",
       "          [-1.2273e-01, -1.1066e-01, -6.2778e-02,  ..., -4.2943e-02,\n",
       "           -4.1240e-02,  3.8275e-02],\n",
       "          [-1.3837e-01, -1.5941e-01, -1.0918e-01,  ..., -1.2720e-01,\n",
       "           -3.5413e-02, -7.1518e-02],\n",
       "          [-1.8999e-01, -1.7232e-01, -2.2175e-01,  ..., -5.6922e-02,\n",
       "           -1.4705e-01, -1.3118e-01]],\n",
       "\n",
       "         [[-6.0491e-02, -6.7236e-02, -6.3126e-02,  ..., -1.6559e-02,\n",
       "            1.5182e-02, -6.6281e-02],\n",
       "          [-4.7476e-03,  8.6532e-04, -3.5418e-02,  ...,  1.2285e-02,\n",
       "            6.7559e-03, -2.0604e-02],\n",
       "          [-6.0211e-02, -6.9398e-02, -7.3843e-02,  ..., -2.8495e-04,\n",
       "            2.6373e-02, -9.6901e-03],\n",
       "          ...,\n",
       "          [ 8.0451e-03,  3.6576e-02,  3.2826e-02,  ...,  6.2249e-02,\n",
       "            3.6571e-02,  5.5310e-02],\n",
       "          [ 1.6799e-02,  6.8567e-02,  7.1977e-02,  ...,  5.2158e-02,\n",
       "            3.3092e-02, -4.5646e-04],\n",
       "          [-1.4754e-02,  5.9634e-02,  2.5752e-02,  ...,  3.9922e-02,\n",
       "            4.0176e-02,  3.0629e-02]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[-2.4450e-01, -1.3500e-01, -6.0904e-02,  ..., -6.5794e-02,\n",
       "           -6.6147e-02, -1.1316e-01],\n",
       "          [-1.3372e-01, -8.8736e-03,  2.3152e-02,  ..., -2.8546e-02,\n",
       "           -3.7057e-02, -7.2311e-02],\n",
       "          [-5.1490e-02,  8.0534e-02,  6.6972e-02,  ..., -5.2036e-02,\n",
       "           -1.8634e-02, -1.2554e-01],\n",
       "          ...,\n",
       "          [-5.0637e-03, -6.3580e-03,  6.9080e-03,  ...,  1.0932e-02,\n",
       "            1.7018e-04, -3.7493e-02],\n",
       "          [-1.4052e-02,  2.9303e-02, -1.4004e-02,  ...,  2.3600e-02,\n",
       "           -2.8451e-03, -7.4469e-02],\n",
       "          [-7.7849e-02, -5.1993e-02,  9.6142e-02,  ...,  3.8551e-02,\n",
       "            7.5623e-03, -3.5416e-02]],\n",
       "\n",
       "         [[ 7.7539e-03,  9.0136e-02,  1.0481e-01,  ...,  4.3200e-03,\n",
       "            1.0460e-01,  4.0172e-02],\n",
       "          [ 1.3043e-01,  1.9272e-01,  2.3092e-01,  ...,  1.7324e-01,\n",
       "            1.6418e-01,  1.6919e-01],\n",
       "          [ 9.4426e-02,  1.4135e-01,  1.9681e-01,  ...,  1.8512e-01,\n",
       "            1.7613e-01,  2.1799e-01],\n",
       "          ...,\n",
       "          [ 1.1112e-01,  1.6993e-01,  1.2888e-01,  ...,  1.3010e-01,\n",
       "            2.2520e-01,  2.1793e-01],\n",
       "          [ 4.6389e-02,  9.0685e-02,  1.8727e-01,  ...,  1.0935e-01,\n",
       "            1.2386e-01,  1.2481e-01],\n",
       "          [ 1.0194e-02,  8.9554e-02,  1.8034e-01,  ...,  1.9394e-01,\n",
       "            1.1735e-01,  1.5078e-01]],\n",
       "\n",
       "         [[-6.7367e-02, -4.5177e-03,  8.6995e-03,  ..., -6.6786e-02,\n",
       "           -6.4555e-02, -1.4474e-01],\n",
       "          [-7.3313e-02, -3.8734e-03, -4.4528e-02,  ...,  1.7147e-02,\n",
       "            1.1520e-01, -5.8048e-03],\n",
       "          [-4.7035e-02,  5.7789e-02,  2.3285e-02,  ...,  6.4702e-02,\n",
       "            5.3005e-02, -1.8384e-02],\n",
       "          ...,\n",
       "          [-6.8184e-02, -8.3493e-02,  4.8231e-02,  ...,  3.0795e-02,\n",
       "            6.3039e-02, -2.2964e-02],\n",
       "          [ 1.2477e-02, -1.3230e-02,  1.7078e-02,  ...,  5.8328e-02,\n",
       "            8.0495e-02,  4.6703e-02],\n",
       "          [ 2.2657e-02, -5.8770e-02,  3.2854e-02,  ..., -3.3346e-02,\n",
       "           -6.9203e-02, -1.7536e-02]]],\n",
       "\n",
       "\n",
       "        [[[-2.5101e-02, -1.2342e-02, -2.9671e-02,  ..., -1.4390e-02,\n",
       "           -2.2443e-02, -2.2674e-02],\n",
       "          [-7.4371e-03, -1.8698e-02, -8.4577e-03,  ..., -3.0067e-03,\n",
       "           -1.2724e-02, -1.5078e-02],\n",
       "          [-2.2665e-02, -1.7330e-02, -1.3231e-02,  ..., -1.1093e-02,\n",
       "           -1.6007e-02, -1.2297e-02],\n",
       "          ...,\n",
       "          [-1.0733e-02, -1.1727e-02, -4.6482e-03,  ..., -1.1591e-02,\n",
       "           -9.1225e-03, -1.3354e-02],\n",
       "          [-1.3690e-02, -9.0526e-03, -5.4001e-03,  ..., -3.2978e-03,\n",
       "           -4.3404e-04, -1.5239e-02],\n",
       "          [-1.6919e-02, -1.4559e-02, -1.4062e-02,  ..., -9.6292e-03,\n",
       "           -1.4523e-02, -1.8981e-02]],\n",
       "\n",
       "         [[ 1.5847e-02, -3.1089e-02, -1.3089e-02,  ...,  2.8779e-02,\n",
       "            4.2272e-03, -1.2216e-01],\n",
       "          [ 7.5989e-03, -1.3331e-01, -8.1789e-02,  ...,  2.5868e-02,\n",
       "            1.1440e-02,  5.5072e-02],\n",
       "          [-8.1420e-02, -8.3569e-02, -1.7731e-01,  ..., -9.0318e-02,\n",
       "           -1.4037e-02,  5.6896e-02],\n",
       "          ...,\n",
       "          [-1.8225e-01, -1.6034e-01, -5.5102e-02,  ..., -8.0227e-02,\n",
       "           -1.0663e-01, -5.6540e-02],\n",
       "          [-1.0831e-01, -9.9569e-02, -1.5681e-01,  ..., -1.4670e-01,\n",
       "           -7.6445e-02,  2.4566e-02],\n",
       "          [-2.5390e-01, -2.1794e-01, -2.2359e-01,  ..., -2.6923e-01,\n",
       "           -1.8856e-01, -1.2864e-01]],\n",
       "\n",
       "         [[-2.4478e-02, -8.7803e-02,  9.2730e-03,  ..., -1.6605e-02,\n",
       "           -8.6414e-03, -6.5235e-02],\n",
       "          [ 3.3698e-02,  2.2059e-03, -3.6803e-03,  ...,  4.6809e-02,\n",
       "            2.3473e-02, -2.1154e-02],\n",
       "          [ 4.3055e-02, -4.7997e-02, -1.8781e-02,  ...,  1.3542e-02,\n",
       "            7.1738e-02,  5.3693e-02],\n",
       "          ...,\n",
       "          [ 3.1118e-03,  3.1700e-02,  7.6805e-03,  ...,  3.9195e-02,\n",
       "            6.0166e-02,  1.4328e-02],\n",
       "          [ 1.1909e-02, -1.1267e-02,  3.1154e-04,  ...,  7.5226e-02,\n",
       "            5.4837e-02,  1.7219e-02],\n",
       "          [ 9.4159e-03,  1.7725e-02,  1.5678e-02,  ...,  5.0439e-02,\n",
       "            4.3819e-02,  1.1497e-02]],\n",
       "\n",
       "         ...,\n",
       "\n",
       "         [[-9.2373e-02, -6.5637e-02, -1.2151e-01,  ..., -8.8421e-03,\n",
       "           -3.6416e-02, -4.7679e-02],\n",
       "          [-1.0602e-01, -6.9161e-02, -9.7080e-02,  ..., -1.7811e-01,\n",
       "           -1.9238e-01, -1.4816e-01],\n",
       "          [-1.3809e-01, -7.1755e-02, -4.6897e-02,  ...,  5.9204e-02,\n",
       "            5.9028e-02,  5.0614e-02],\n",
       "          ...,\n",
       "          [-6.0057e-02,  4.8159e-02,  2.9118e-02,  ..., -9.1935e-02,\n",
       "           -2.4538e-02,  6.1481e-02],\n",
       "          [-8.4472e-02,  5.0429e-02,  2.7359e-02,  ..., -4.2693e-02,\n",
       "            1.2299e-03,  4.7991e-02],\n",
       "          [-5.2604e-02, -3.0945e-03,  8.1414e-02,  ..., -8.0167e-02,\n",
       "           -1.1366e-02, -7.7411e-03]],\n",
       "\n",
       "         [[ 5.4965e-02,  1.2747e-01,  1.2243e-01,  ...,  1.1394e-01,\n",
       "            1.0125e-01,  9.7150e-02],\n",
       "          [ 5.4096e-02,  2.0042e-01,  2.0059e-01,  ...,  1.1121e-01,\n",
       "            1.0226e-01,  2.0992e-01],\n",
       "          [ 6.6260e-02,  1.8967e-01,  2.6544e-01,  ...,  2.4330e-01,\n",
       "            2.3499e-01,  3.1968e-01],\n",
       "          ...,\n",
       "          [ 1.5713e-01,  2.2551e-01,  9.2421e-02,  ...,  9.8356e-02,\n",
       "            1.8485e-01,  2.1446e-01],\n",
       "          [ 8.2651e-02,  1.4126e-01,  1.7996e-01,  ...,  1.2379e-01,\n",
       "            1.7639e-01,  2.0959e-01],\n",
       "          [ 9.4599e-02,  9.7819e-02,  2.3556e-01,  ...,  1.2236e-01,\n",
       "            1.3354e-01,  1.5799e-01]],\n",
       "\n",
       "         [[ 1.2069e-02,  1.3634e-02,  1.1795e-02,  ...,  3.2111e-02,\n",
       "            4.6013e-02,  8.1123e-02],\n",
       "          [-1.0531e-02, -2.3113e-02, -4.8540e-02,  ...,  2.7631e-02,\n",
       "           -7.1259e-03, -8.7336e-02],\n",
       "          [-6.8734e-02, -3.7876e-03,  8.8992e-03,  ..., -2.7733e-02,\n",
       "           -3.3833e-03, -5.9414e-02],\n",
       "          ...,\n",
       "          [ 1.5382e-02,  1.8501e-02,  7.3591e-02,  ..., -3.0775e-02,\n",
       "            4.0859e-02,  3.5695e-03],\n",
       "          [ 5.1012e-03,  4.9343e-02, -4.1293e-02,  ...,  1.0299e-01,\n",
       "            9.0207e-02, -7.7692e-02],\n",
       "          [-1.0827e-01, -4.2990e-02,  3.4179e-02,  ...,  9.2493e-03,\n",
       "            3.1847e-02, -3.0161e-02]]]], device='cuda:0',\n",
       "       grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoder(image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 100/100 [02:30<00:00,  1.50s/it]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm \n",
    "import time \n",
    "\n",
    "for _ in tqdm(range(100), mininterval=10): \n",
    "    time.sleep(1.5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mpfrwilson\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.16.1 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.15.11"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/fs01/home/pwilson/projects/sam_cancer_detection/wandb/run-20231207_005720-12345678</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/pfrwilson/test/runs/12345678' target=\"_blank\">peachy-moon-77</a></strong> to <a href='https://wandb.ai/pfrwilson/test' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/pfrwilson/test' target=\"_blank\">https://wandb.ai/pfrwilson/test</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/pfrwilson/test/runs/12345678' target=\"_blank\">https://wandb.ai/pfrwilson/test/runs/12345678</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/pfrwilson/test/runs/12345678?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x7f45bb0b7f50>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os \n",
    "os.environ['WANDB_RUN_ID'] = \"12345678\"\n",
    "\n",
    "import wandb\n",
    "wandb.init(project='test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ai",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
